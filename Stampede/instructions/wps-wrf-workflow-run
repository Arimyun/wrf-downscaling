Each step will depend on the output of the previous step.
Data files should be put in the $SCRATCH folder, and model files should be put in your home directory

Step 1:
    geog.exe        // Get the full geog data set zip file from
                    // http://www2.mmm.ucar.edu/wrf/users/download/get_sources_wps_geog.html
                Geog Data get:
                    wget http://www2.mmm.ucar.edu/wrf/src/wps_files/geog_complete.tar.bz2 
                    tar -xvjf geog_complete.tar.bz2 
                    The files have been saved at data folder
                    
                Edit namelist.wps file to link the correct geog_data_path
                Create geogrid.script file to submit slurm job
                    sbatch geogrid.script
    output: geo_em.d01.nc, geo_em.d02.nc and geo_em.d03.nc

Step 2:
    
        use python script to download grib data. (Need registration and put private API key at local home directory)
            Use a dedicated server to download grib eraint data
            get python file: era-int/retrieve_eraint_data_for_wps.py
        Need to install ecmwfapi module
            go to website: https://software.ecmwf.int/wiki/display/WEBAPI/Accessing+ECMWF+data+servers+in+batch
                1. download ecmwfapi module
                2. register account
                3. follow procedue to install your API Key (create .ecmwfapirc configuration file)
                4. new users need to sign an agreement on their website (if you face 403 Forbidden)
            python era-int/retrieve_eraint_data_for_wps.py --strt_dt='1987-09-30' --end_dt='1987-10-02'
        Transfer data from local to Stampede
            Scp ERA-* files from local dedicated data server to Stampede (../WRF/ERA)
            
    Use link_grib.csh to link all .grb file. (link_grib.csh is at the folder Build_WPS/WPS)
            ./link_grib.csh /work/03084/taolin1/WRF/ERA/E (ERA file directory with the file starting name E)
        
    Edit namelist.wps file to make sure the simulation time horizon is consistent with the data
            # hint: the required data input needs to be one day earlier than the simulatio horizon
    
    Link the correct VTable
            ln -s ungrib/Variable_Tables/Vtable.ERA-interim.pl Vtable
                    // copy Vtable from GitHub to Build_WPS/WPS ( might not be correct)
                    // (https://github.com/ebimodeling/wrf-downscaling/blob/master/era-int/Vtable)
    
    Run ungrib.exe (twice with different namelist.wps in &ungrib section)              
                
        Submit two job scripts: (run ungrib.exe)
            1.  copy inv_landseamask.grb file from GitHub to WRF/ERA)
                Use link_grib.csh to link all .grb file. (link_grib.csh is at the folder Build_WPS/WPS)
                    ./link_grib.csh /work/03084/taolin1/WRF/ERA/*.grb 
                Edit namelist.wps
                        &ungrib
                            out_format = 'WPS',
                            prefix = 'LSM',
                Create ungrib.script file to submit slurm job
                    sbatch ungrib.script
                    
            2.  copy inv_geopotential2.grb file from GitHub to WRF/ERA
                remove inv_landseamask.grb
                    ./link_grib.csh /work/03084/taolin1/WRF/ERA/*.grb 
                Edit namelist.wps
                        &ungrib
                            out_format = 'WPS',
                            prefix = 'Z',
                Create ungrib.script file to submit slurm job
                    sbatch ungrib.script
    
   

    output: LSM:${datetime_each_interval} and Z:${datetime_each_interval}
    datetime_each_interval examples: 2008-01-07_00, 2008-01-07_06, 2008-01-07_12 ... (6 hours interval)

Step 3:
    metgrid.exe     //  change namelist for input files generated by Step 2 in &metgird section
                    //  check to link correct .TBL files (Source from wrf-downscaling/install/METGRID.TBL)
    
    Create metgrid.script file
    edit namelist $metgrid section to link the correct Z and LSM files
            any good approach for this particular edits for long-time running?
    Submit job
            sbatch metgrid.script
    
    output: met_em.d01.${datetime_each_interval_with_mins_secs}.nc
            met_em.d02.${datetime_each_interval_with_mins_secs}.nc
            met_em.d03.${datetime_each_interval_with_mins_secs}.nc

    datetime_each_interval_with_mins_secs examples: 2008-01-07_00:00:00, 2008-01-07_06:00:00, 2008-01-07_12:00:00 (6 hours interval)

Step 4:
    real.exe        // put namelist.input, nam_io_d01.txt, nam_io_d02.txt, nam_io_d03.txt in position
        create a new directory in work directory (/work/../WRF/em_real)
        move metgrid output files (met_em.d0*.nc) to work directory
       
        get related input configuration files (*d01.txt,*d02.txt,*d03.txt) from Github
            wget https://github.com/ebimodeling/wrf-downscaling/blob/master/Stampede/namelist/nam_io_d01.txt
        get namelist.input from Github
            wget https://github.com/ebimodeling/wrf-downscaling/blob/master/install/namelist.input
        edit namelist.input to make sure simulation time horizon is correct
        check diff_opt  //diffusion option is on or not
        
        create real.script 
        sbatch real.script
    output: wrfbdy_d01, wrffdda_d01, wrfinput_d01, wrfinput_d02, wrfinput_d03, wrflowinp_d01, wrflowinp_d02, wrflowinp_d03

Step 5:
    wrf.exe         // a bunch of configuration files in folder /work/01701/yefan/WRF/em_real
                    // they were copied from David's run folder on Blacklight. Most names of them start with a capital letter.
        
        download necessary configuration files into folder /work/../WRF/em_real
            https://github.com/ebimodeling/wrf-downscaling/tree/master/Stampede/wrf-configuration-files
        create wrf.script
        sbatch wrf.script
        


    output: wrfout_d01_${datetime_each_interval_with_mins_secs}
            wrfrst_d01_${datetime_each_interval_with_mins_secs}
            wrfout_d02_${datetime_each_interval_with_mins_secs}
            wrfrst_d02_${datetime_each_interval_with_mins_secs}
            wrfout_d03_${datetime_each_interval_with_mins_secs}
            wrfrst_d03_${datetime_each_interval_with_mins_secs}
